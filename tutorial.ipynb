{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97efc51-d3ca-4a93-8040-a16d541c6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statannotations scikit-learn-intelex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef08229-5db6-424e-8cc6-54bf176a8dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.pipeline \n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.neural_network\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import gensim.models \n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "from statannotations.Annotator import Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c6f33-40a6-4ec3-b094-4b5c47b771d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'xtick.labelsize': 14, 'ytick.labelsize': 14, \n",
    "                     'axes.titlesize':14, 'axes.labelsize':16}) #default font sizes for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfc07f-f17d-4234-bd6c-f8cec90d7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data.tar 'https://drive.google.com/uc?export=download&id=12ekhGbgMPGYSX-t6mFR5TEgxGF46-sQ_'\n",
    "!tar -xvf data.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784e76b-6108-4a98-8726-4c0ecd35c1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f22e37-011e-4788-a038-719f49e0bb73",
   "metadata": {},
   "source": [
    "# MPRA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3c88a-912e-42d0-9581-99c23a6845c7",
   "metadata": {},
   "source": [
    "We are going to predict data from a massively parallel reporter assay (MPRA) study (Griesemer et al. 2021):\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/Ers7U2YVgAI-BDG?format=jpg&name=large\" width=70% />\n",
    "\n",
    "We will treat Ref and Alt seqeunces independently and predict reporter expression in HMEC cells for each seqeunce using regression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71a28b-a07d-4696-9db0-1c8901df3d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpra_df = pd.read_csv(data_dir + 'mpra_HMEC.csv') #sequence info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f6b60-12a3-48aa-9a7b-8dab7d4c083c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpra_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f1358-d6a4-45ab-9448-10e191b370a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(mpra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3996e2-d7d6-46c5-b5d5-049b9c847a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = mpra_df.Expression.hist(bins='auto',figsize=(6,3))\n",
    "\n",
    "ax.set_xlabel('MPRA expression Log2FC')\n",
    "ax.set_ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb008eea-f437-4b16-9775-b457204c954b",
   "metadata": {},
   "source": [
    "The predictions will be based on embeddings, obtained for each seqeunce via a masked language model (MLM) (Gankin et al. 2023). MLM is an unsupervised model which we specifically retrained to reconstruct masked nucleotides in DNA seqeunces of mammalian 3'UTR regions. \n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/FntnrCzXgAEUMh3?format=jpg&name=medium\" width=70% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f348c-7a92-48e3-a888-df9b947e82eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlm_embeddings = np.load(data_dir + \"mpra_MLM.npy\") #masked language model embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87beae0-fa72-404f-a0b7-38892e40f29e",
   "metadata": {},
   "source": [
    "# Compare regression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78011edf-ac03-4c32-b556-bb36e9394650",
   "metadata": {},
   "source": [
    "We will first compare a few common machine learning regression algorithms: Ridge (L2) regression, multilayer perceptron (MLP), and support vector regression (SVR). \n",
    "\n",
    "Nested Cross-Validation is a common approach to compare different machine-learning algorithms. \n",
    "The outer loop serves to estimate the algorithm performance and the inner loop is used to tune hyper-parameters.\n",
    "When the best performing algorithm is chosen,  hyperparameter tuning is performed again in a single CV loop over the whole available data. The final model is then obtained via training with the resulting hyperparamaters on all the data. To report the estimated performance, the score obtained at the 1st step with the Nested CV can be used.\n",
    "\n",
    "<img src=\"https://hackingmaterials.lbl.gov/automatminer/_images/cv_nested.png\" width=70% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2b841-8217-4a23-b0c6-8a9e3ba724cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNestedCV():\n",
    "    \n",
    "    '''\n",
    "    Group Nested Cross-Validation\n",
    "    \n",
    "    Parameters:\n",
    "    clf: sklearn-compatible classifier\n",
    "    hpp_search_grid: dictionary of parameter values for hyperparameter search\n",
    "    \n",
    "    if hpp_search_grid is None, just perform Group k-fold CV\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, clf, hpp_search_grid=None, n_splits = 10):\n",
    "        \n",
    "        self.clf = clf\n",
    "        self.hpp_search_grid = hpp_search_grid\n",
    "        self.group_kfold = sklearn.model_selection.GroupKFold(n_splits=n_splits)\n",
    "        \n",
    "    def run(self, X, y, groups):\n",
    "    \n",
    "        '''\n",
    "        Iterates over  self.group_kfold folds and performs hyperparameter search within each fold\n",
    "\n",
    "        Returns:\n",
    "        Predictions for all folds\n",
    "        '''\n",
    "\n",
    "        kfold_scores = [] #predictions in all folds\n",
    "\n",
    "        #outer loop\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(self.group_kfold.split(X, y, groups)):\n",
    "\n",
    "            X_train, y_train, groups_train = X[train_idx,:], y[train_idx], groups[train_idx]\n",
    "\n",
    "            X_test, y_test = X[test_idx,:], y[test_idx]\n",
    "\n",
    "            if self.hpp_search_grid!=None:\n",
    "\n",
    "                print(f'Hyperparameter search in fold {fold_idx}')\n",
    "\n",
    "                gs = sklearn.pipeline.make_pipeline(StandardScaler(),\n",
    "                                                sklearn.model_selection.GridSearchCV(self.clf, self.hpp_search_grid, cv=3))\n",
    "\n",
    "                gs.fit(X_train, y_train, gridsearchcv__groups = groups_train)\n",
    "\n",
    "                best_params = gs['gridsearchcv'].best_params_\n",
    "                print(f'Best hyperparameters: {best_params}')\n",
    "\n",
    "            #train \n",
    "            pipe = sklearn.pipeline.make_pipeline(...)\n",
    "            pipe.fit(X_train, y_train)\n",
    "            \n",
    "            #inference\n",
    "            y_pred = pipe.predict(X_test)\n",
    "\n",
    "            kfold_scores.append(np.vstack(([fold_idx]*len(y_test),y_pred,y_test))) #add predictions for the current fold\n",
    "\n",
    "        return kfold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f007a-f212-477d-9d35-0aa5d0204e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algs = {} #algorithms to test\n",
    "hpp_search_space = {} #hyperparameter search space for each model\n",
    "\n",
    "algs['ridge'] = sklearn.linear_model.Ridge()\n",
    "hpp_search_space['ridge'] = {'alpha':10.**np.arange(-10,10)}\n",
    "              \n",
    "algs['MLP'] = sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(64,32,16,), alpha=10, \n",
    "                 batch_size=1000, learning_rate_init=5e-4, max_iter=300, shuffle=False)\n",
    "\n",
    "algs['SVR'] = sklearn.svm.SVR(C=4, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df25c32-92e9-4124-bfff-5c4a569c0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mlm_embeddings #MLM embeddings\n",
    "y = mpra_df['Expression'].values #dependent variable\n",
    "groups = mpra_df['group'].values #groups (genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffa185-b283-44e1-bb0e-b436e28ccfde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_mpra = []\n",
    "\n",
    "for model, alg in algs.items():\n",
    "    \n",
    "    print(f'MODEL: {model}')\n",
    "    \n",
    "    group_nested_cv = GroupNestedCV(alg, hpp_search_space.get(model,None), )\n",
    "    \n",
    "    scores = group_nested_cv.run(X, y, groups)\n",
    "    \n",
    "    scores = pd.DataFrame(np.hstack(scores).T, columns=['fold','y_pred','y_test']) #numpy array to DataFrame\n",
    "    \n",
    "    scores['model'] = model #add model column\n",
    "    \n",
    "    preds_mpra.append(scores)#stack dataframes of different models\n",
    "\n",
    "preds_mpra = pd.concat(preds_mpra)#concatenate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93bfeb-df2d-4db3-87c5-09180046521c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_mpra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0ad13-ddb1-4d63-96ce-b2f9e89774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_test, y_pred):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d0ec9-fd6c-4814-a9c4-796d7c6a9202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_fold_scores = preds_mpra.groupby(['model','fold']).apply(lambda x: r2_score(x.y_test,x.y_pred)).rename('score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa56592-d7d6-4662-8d6e-6ed8b877af46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "ax = sns.swarmplot(data=per_fold_scores, x=\"model\", y=\"score\") #scatter plot\n",
    "ax = sns.boxplot(data=per_fold_scores, x=\"model\", y=\"score\", boxprops={'facecolor':'None'})\n",
    "\n",
    "box_pairs=[ (\"MLP\", \"SVR\"), (\"MLP\", \"ridge\"), (\"SVR\", 'ridge')]\n",
    "\n",
    "annotator = Annotator(ax, box_pairs, data=per_fold_scores, x=\"model\", y=\"score\")\n",
    "annotator.configure(test='Wilcoxon', text_format='star', loc='inside')\n",
    "\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"score\")\n",
    "ax.tick_params(rotation=30)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f373c-2939-4547-834a-cbb9119abbf2",
   "metadata": {},
   "source": [
    "An alternatlive way to compare models: pool predictions from all CV folds and pretend that they are obtained from a single test set.\n",
    "Then the error for each model and each observation is computed. Afterwards, a statistical test is preformed to determine if the average error from one model is greater than the average error from another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a69da-6a25-46be-8d52-f1bcce7045cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_mpra['error'] = abs(preds_mpra.y_pred-preds_mpra.y_test) #absolute errors for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f282d4-08be-44a2-9ffc-8b4b489cf043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_mpra.groupby('model').error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0697e-eddf-4456-bbd8-3236c3ecf295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comp1 = mc.MultiComparison(preds_mpra['error'], preds_mpra['model'])\n",
    "tbl, a1, a2 = comp1.allpairtest(stats.wilcoxon, method= \"bonf\")\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d62dd-9b5c-4a69-8922-c5a4883d5e86",
   "metadata": {},
   "source": [
    "Despite being very popular, both approaches violate the sample independence assumption: each sample is used to train 9 out of 10 models (for 10-fold CV), so neither per-fold scores nor single pooled observations are completely independent.\n",
    "\n",
    "See hte followig paper for more details:\n",
    "\n",
    "Dietterich, Thomas G. \"Approximate statistical tests for comparing supervised classification learning algorithms.\" Neural computation 10.7 (1998): 1895-1923."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec7164-adca-4eb1-a5bd-8767976a09af",
   "metadata": {},
   "source": [
    "# Comparing with other embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbabec-a2a7-48ac-88b5-a7b45dca21e3",
   "metadata": {},
   "source": [
    "We shall also try to predict MPRA expression from alternative embeddings: 4-mer counts and a Word2Vec model.\n",
    "\n",
    "For this, we need to define some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c93e0-559a-434c-a65c-e4384d7f0e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Kmerizer:\n",
    "    '''\n",
    "    Helper class to generate k-mers and Word2Vec embeddings\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        #generate all possible k-mers out of 4 characters, e.g. ACGTC, GTACC, etc.. for k=5\n",
    "        \n",
    "        ...\n",
    "\n",
    "        self.kmers = {kmer:idx for idx,kmer in enumerate(kmers)}\n",
    "        \n",
    "    def kmerize(self, seq):\n",
    "        '''\n",
    "        Count all k-mers in the sequence \n",
    "        Returns:\n",
    "        A list with counts corresponding to each possible k-mer from self.kmers\n",
    "        e.g. for k=2 and seq='ACTAC'\n",
    "        > [0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "        '''\n",
    "        counts = [0]*4**self.k\n",
    "        for i in range(len(seq) - self.k + 1): \n",
    "            kmer = seq[i:i+self.k]\n",
    "            counts[self.kmers[kmer]] += 1\n",
    "        return counts\n",
    "    \n",
    "    def tokenize(self, seq):\n",
    "        '''\n",
    "        Get all k-mers in the sequence\n",
    "        Returns:\n",
    "        A list of all k-mers\n",
    "        e.g. for 2-mers and seq='ACTAC' \n",
    "        > ['AC', 'CT', 'TA', 'AC']\n",
    "        '''\n",
    "        kmers = []\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4b708-dc85-4908-b7de-57590e89f9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2vec_model(mpra_df):\n",
    "    \n",
    "    '''\n",
    "    Word2Vec model\n",
    "    \n",
    "    k-mers are defined through their context: \n",
    "    k-mers with similar context will have similar embeddings\n",
    "    '''\n",
    "    \n",
    "    kmerizer_w2v = Kmerizer(k=4)\n",
    "    \n",
    "    w2v_model = gensim.models.Word2Vec(sentences=mpra_df.seq.apply(lambda x: kmerizer_w2v.tokenize(x)), \n",
    "                         vector_size=128, window=5, min_count=1, workers=4, sg=1) #default: CBOW\n",
    "\n",
    "    word2vec_emb = mpra_df.seq.apply(\n",
    "        lambda x: np.mean([w2v_model.wv[x]  for x in kmerizer_w2v.tokenize(x)],axis=0)) #average embedding of all 4-mers in the sequence\n",
    "\n",
    "    X = np.stack(word2vec_emb,axis=0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b1e5d-7a49-4892-a409-0cb9d3c504a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_matrices = {} #embeddings dictionary\n",
    "\n",
    "data_matrices['MLM'] = mlm_embeddings\n",
    "\n",
    "kmerizer4 = Kmerizer(k=4)\n",
    "data_matrices['4-mers'] = np.stack(mpra_df.seq.apply(lambda x: kmerizer4.kmerize(x))) \n",
    "\n",
    "data_matrices['Word2Vec'] = word2vec_model(mpra_df)\n",
    "\n",
    "y = mpra_df['Expression'].values\n",
    "groups = mpra_df['group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda22aa-8595-481d-9a47-50a68b19a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = sklearn.svm.SVR(C=4, epsilon=0.1)\n",
    "\n",
    "preds_mpra = []\n",
    "\n",
    "for model, X in data_matrices.items():\n",
    "    \n",
    "    print(f'MODEL: {model}')\n",
    "    \n",
    "    group_nested_cv = GroupNestedCV(alg)\n",
    "    \n",
    "    scores = group_nested_cv.run(X, y, groups)\n",
    "    \n",
    "    scores = pd.DataFrame(np.hstack(scores).T, columns=['fold','y_pred','y_test']) #numpy array to DataFrame\n",
    "    \n",
    "    scores['model'] = model #add model column\n",
    "    \n",
    "    preds_mpra.append(scores)#stack dataframes of different models\n",
    "\n",
    "preds_mpra = pd.concat(preds_mpra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0f3f9-2544-4dd2-8446-f0837c787349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_fold_scores = preds_mpra.groupby(['model','fold']).apply(lambda x: sklearn.metrics.r2_score(x.y_test,x.y_pred)).rename('score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde2583-1b77-443f-a662-48e2dc36b373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "ax = sns.swarmplot(data=per_fold_scores, x=\"model\", y=\"score\") #scatter plot\n",
    "ax = sns.boxplot(data=per_fold_scores, x=\"model\", y=\"score\", boxprops={'facecolor':'None'})\n",
    "\n",
    "box_pairs=[ (\"MLM\", \"4-mers\"), (\"MLM\", \"Word2Vec\"), (\"4-mers\", \"Word2Vec\")]\n",
    "\n",
    "annotator = Annotator(ax, box_pairs, data=per_fold_scores, x=\"model\", y=\"score\")\n",
    "annotator.configure(test='Wilcoxon', text_format='star', loc='inside', comparisons_correction=\"BH\")\n",
    "#annotator.configure(test='t-test_paired', text_format='star', loc='inside', comparisons_correction=\"BH\")\n",
    "\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"score\")\n",
    "ax.tick_params(rotation=30)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339f16f-1dbb-4c17-9081-6e126bedf0a7",
   "metadata": {},
   "source": [
    "# Assessing model stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1fea8-3189-473f-b847-9bedfb4cc934",
   "metadata": {
    "tags": []
   },
   "source": [
    "For a stable model, predictions are robust with respect to small changes in the train set (e.g. when including/excluding individual train instances).\n",
    "\n",
    "To assess model stability, one performs repeated Cross-Validation: at each round the dataset is split into the same number of folds, but the exact fold composition is different. Then variance in predictions for each test point are estimated.\n",
    "\n",
    "Example for classification (https://stats.stackexchange.com/questions/551242):\n",
    "\n",
    "<img src=\"img/stability.png\" width=70% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8429ee-6336-4d9a-b238-c50a9c7dbf32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mlm_embeddings\n",
    "y = mpra_df['Expression'].values\n",
    "groups = mpra_df['group'].values\n",
    "\n",
    "pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(), \n",
    "                     sklearn.linear_model.Ridge(alpha=100)) \n",
    "\n",
    "#pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(), \n",
    "#                     sklearn.svm.SVR(C=4, epsilon=0.1))\n",
    "\n",
    "#pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(), \n",
    "#                sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(64,32,16,), alpha=10, batch_size=1000, learning_rate_init=5e-4, max_iter=500, shuffle=False))\n",
    "\n",
    "N_rounds = 50 #number of CV rounds\n",
    "N_splits = 10 #number of CV splits in each round\n",
    "\n",
    "N_instances = len(y) #total number of test points equals dataset size\n",
    "\n",
    "cv_res = np.zeros((N_rounds*N_splits,N_instances)) #CV predictions for each point\n",
    "cv_res[:] = np.NaN \n",
    "\n",
    "cv_scores = [] # score for each fold in each round, N_rounds X N_splits\n",
    "\n",
    "for round_idx in range(N_rounds):\n",
    "    \n",
    "    print(f'CV round {round_idx}')\n",
    "\n",
    "    gss = sklearn.model_selection.GroupShuffleSplit(n_splits=N_splits, train_size=.9, random_state = round_idx) #10-fold CV\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(gss.split(X, y, groups)):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = X[train_idx,:],X[test_idx,:],y[train_idx],y[test_idx]\n",
    "        \n",
    "        pipe.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "            \n",
    "        cv_res[round_idx*N_splits+fold_idx,test_idx] = y_pred #predictions for test instances in this fold in this round\n",
    "        \n",
    "        cv_scores.append((sklearn.metrics.r2_score(y_test,y_pred), round_idx)) #score for this fold in this round\n",
    "        \n",
    "cv_scores = pd.DataFrame(cv_scores, columns=['score', 'CV round'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c0a09-ee62-4b59-bca9-63188f2936f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "cv_scores['model'] = 'MLM'\n",
    "\n",
    "ax = sns.swarmplot(data=cv_scores[cv_scores['CV round']<10],y='score',x='model',hue=\"CV round\", palette=\"deep\")\n",
    "ax = sns.boxplot(data=cv_scores,y='score',x='model', boxprops={'facecolor':'None'})\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa3991-f33c-42a9-97af-87b8abda54ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,5, figsize=(10,2))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "samples = np.random.choice(a=range(len(y)),size=5) #choose 5 random test points\n",
    "\n",
    "for ax,sample_idx in zip(axes,samples):\n",
    "    #sns.kdeplot(x=cv_res[:,sample_idx], ax=ax)\n",
    "    sns.swarmplot(x=cv_res[:,sample_idx], ax=ax)\n",
    "    sns.boxplot(x=cv_res[:,sample_idx], ax=ax, boxprops={'facecolor':'None'})\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(axis='x', which='major', labelsize=8)\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.plot(y[sample_idx]*np.ones((50,)),np.linspace(*ylims), linestyle='--', color='tab:orange') #y_true\n",
    "    ax.set_title(f'sample {sample_idx}')\n",
    "    ax.set_xlabel('y_pred')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034be5ee-5f16-4ca7-94ed-332f0dfb392a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can evaluate model instability by computing the average coefficient of variation over test points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52f793-3641-48ba-ba9a-ebd1b7620820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = ... #coefficient of variation of each test point due to change in train set distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8745868-122e-4234-914b-c83b919aa693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abs(cv).mean() #measure of model instability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c670cfe-7459-4095-960d-1ea9a1272e54",
   "metadata": {},
   "source": [
    "When choosing models, we prefer stable ones.\n",
    "\n",
    "How to fight instability?\n",
    "\n",
    "- add regularization\n",
    "- use stable algorithms\n",
    "- reduce the number of features through feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57808a8-7620-4844-9ccc-f63c920cbc03",
   "metadata": {},
   "source": [
    "How to estimate generalization performance of an unstable model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7bb10-176f-4b4f-b120-9f0b57cd3446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_per_round = cv_scores.groupby('CV round')['score'].mean()#mean score in each round\n",
    "\n",
    "CV_rounds = np.arange(1,N_rounds+1)\n",
    "\n",
    "average_score = np.cumsum(score_per_round)/CV_rounds #cumulative average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a48dc-44cf-439d-b729-682549d93ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(CV_rounds, score_per_round, marker='o', markersize=2, linestyle='') \n",
    "\n",
    "ax.plot(CV_rounds, average_score, markersize=2) \n",
    "\n",
    "ax.set_xlabel('CV rounds')\n",
    "ax.set_ylabel('score')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6b5b7-edc4-47f0-93e3-eeb109d9f236",
   "metadata": {
    "tags": []
   },
   "source": [
    "To estimate generalization performance of an unstable model, one performs repeated K-fold CV. The score is then averaged over all folds and all rounds. The number of repeats can be determined by plotting the averaged performance metric vs the number of rounds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
